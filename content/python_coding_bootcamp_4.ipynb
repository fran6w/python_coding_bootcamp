{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python coding bootcamp - Notebook 4\n",
    "\n",
    "1. Combining data\n",
    "2. Statistical analysis\n",
    "3. The split-apply-combine strategy\n",
    "4. Time series\n",
    "\n",
    "&copy; Francis WOLINSKI 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3><i class=\"fa fa-plus-square\"></i>  PART 1</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# display options\n",
    "pd.set_option(\"display.min_rows\", 16)\n",
    "pd.set_option(\"display.max_columns\", 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 1\n",
    "\n",
    "<h3><i class=\"fa fa-database\"></i></h3>\n",
    "\n",
    "The GeoNames geographical database covers all countries and contains over eleven million placenames that are available for download free of charge.\n",
    "\n",
    "Source: http://download.geonames.org/export/dump/\n",
    "\n",
    "File : <code>cities500.zip</code>\n",
    "\n",
    "All cities with a population > 500 or seats of adm div down to PPLA4 (ca 200,000), see 'geoname' table for columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset 1\n",
    "df = pd.read_csv('data/cities500.zip',\n",
    "                   sep='\\t',\n",
    "                   header=None,\n",
    "                   names=['geonameid', 'name', 'asciiname', 'alternatenames', 'latitude', 'longitude', 'feature class', 'feature code', 'country code', 'cc2', 'admin1 code', 'admin2 code', 'admin3 code', 'admin4 code', 'population', 'elevation', 'dem', 'timezone', 'modification date'],\n",
    "                   dtype={'admin1 code': str, 'admin2 code': str, 'admin3 code': str, 'admin4 code': str})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check columns with NaN\n",
    "df.isna().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which country code is NaN?\n",
    "df.loc[df['country code'].isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reload the dataset with the appropriate option for dealing with the `NA` code which represents Namibia and NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload dataset 1\n",
    "# NA values are only empty strings and -9999 numbers\n",
    "df = pd.read_csv('data/cities500.zip',\n",
    "                   sep='\\t',\n",
    "                   header=None,\n",
    "                   names=['geonameid', 'name', 'asciiname', 'alternatenames', 'latitude', 'longitude', 'feature class', 'feature code', 'country code', 'cc2', 'admin1 code', 'admin2 code', 'admin3 code', 'admin4 code', 'population', 'elevation', 'dem', 'timezone', 'modification date'],\n",
    "                   dtype={'admin1 code': str, 'admin2 code': str, 'admin3 code': str, 'admin4 code': str},\n",
    "                   keep_default_na=False,\n",
    "                   na_values=['', -9999])\n",
    "\n",
    "df.isna().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique values in each column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 2\n",
    "\n",
    "<h3><i class=\"fa fa-database\"></i></h3>\n",
    "\n",
    "Country Codes\n",
    "\n",
    "Source: https://www.geonames.org/countries/\n",
    "\n",
    "The `read_html()` pandas function is able to retrieve all tables from an HTML page. It returns a list of `DataFrame` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# require internet access and lxml\n",
    "if False:\n",
    "    var = pd.read_html('https://www.geonames.org/countries/',\n",
    "                       header=0,\n",
    "                       keep_default_na=False,  # so that \"NA\" which stands for North America is not discarded\n",
    "                       encoding='utf-8'\n",
    "                      )\n",
    "\n",
    "    # display the shapes of the found tables\n",
    "    print([x.shape for x in var])\n",
    "    # get the country DataFrame\n",
    "    df_country = var[1]\n",
    "else:\n",
    "    df_country = pd.read_csv('data/GeoNames.csv', keep_default_na=False)\n",
    "    \n",
    "df_country.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see that the `NA` code is used for a country (Namibia) but also for a continent (North America).\n",
    "\n",
    "There are 7 continents in the dataset: Africa, Europe, Asia, North America, Oceania, South America and Antartica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of countries by continent \n",
    "df_country['Continent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which countries are in AN continent?\n",
    "df_country.loc[df_country['Continent'] == 'AN', 'Country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Combining data\n",
    "\n",
    "The `pandas` library provides functions and methods to combine data.\n",
    "\n",
    "## 1.1 Concatenation\n",
    "\n",
    "It is possible to concatenate several `Series`or `DataFrame` objects:\n",
    "- The `concat()` function takes a list of `Series`or `DataFrame` objects\n",
    "- The option `axis=` can be used to specify whether the concatenation is to be performed vertically or horizontally.\n",
    "- The `concat()` function has already been encountered for concatenating all the US name files (see notebook `python_coding_bootcamp_2`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Merging\n",
    "\n",
    "It is possible to merge 2 `DataFrame` objects by performing a database-style join operation by columns or indexes.\n",
    "- The `merge()` function takes 2 `DataFrame` objects.\n",
    "\n",
    "The database-style join operation requires a column of each `DataFrame` object on which a join will be perfomed and is specified with the `how`option:\n",
    "\n",
    "Merge method | SQL Join Name | Description\n",
    "-|-|-\n",
    "inner | INNER JOIN | Use intersection of keys from both frames\n",
    "left | LEFT OUTER JOIN | Use keys from left frame only\n",
    "right | RIGHT OUTER JOIN | Use keys from right frame only\n",
    "outer | FULL OUTER JOIN | Use union of keys from both frames\n",
    "cross | CROSS JOIN | Cartesian product of both frames\n",
    "\n",
    "By default the join is an `inner` join.\n",
    "\n",
    "As a result, we have a new `DataFrame` with 28 columns: 19 from the cities `DataFrame` and 9 from the countries `DataFrame`. On each line the values of the `country code` and `ISO-3166 alpha2` columns are identical.\n",
    "\n",
    "**Warning**: in the merged `DataFrame` there are 2 columns dealing with population: the column `population` refers to the population of cities and the column `Population` refers to the population of countries. If the column names had been identical, pandas would have added suffixes to their names.\n",
    "\n",
    "Merging and joining 2 `DataFrame` objects have many options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge df and df_countries by iso2\n",
    "# run this cell only once\n",
    "df = pd.merge(df,\n",
    "              df_country,\n",
    "              left_on='country code',\n",
    "              right_on='ISO-3166 alpha2',\n",
    "              how='left')\n",
    "\n",
    "df.to_pickle('df_cities_countries.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the merge: unnecessary of course !\n",
    "(df['country code'] == df['ISO-3166 alpha2']).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of cities by continent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of cities by continent\n",
    "df['Continent'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3><i class=\"fa fa-book\"></i> Further reading</h3>\n",
    "    <ul>\n",
    "        <li><a href='https://pandas.pydata.org/docs/user_guide/merging.html'>Merge, join, concatenate and compare</a></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Statistical analysis\n",
    "\n",
    "## 2.1 The `describe()` method\n",
    "\n",
    "The `describe()` method applied to `Series` or to `DataFrame` objects returns 8 statistical indicators on numerical columns: count, mean, standard deviation, quartiles (25%, 50%, 75%), minimum and maximum.\n",
    "\n",
    "The `describe()` method applied to `Series` objects returns 4 statistical indicators on non numerical dtypes: count, unique, top (most common value), and freq (most common value's frequency).\n",
    "\n",
    "The outpout is an object of same type.\n",
    "\n",
    "This method is useful to get a quick overview of a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe for numerical Series\n",
    "df['population'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe for non numerical Series\n",
    "df['country code'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe for DataFrame\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3><i class=\"fa fa-edit\"></i>  Exercise 1 &starf;</h3>\n",
    "    <ul>\n",
    "        <li>What is the most used city name?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load notebook4/ex_01.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Statistical methods\n",
    "\n",
    "A full set of statistical methods exist and most of them have already been introduced.\n",
    "\n",
    "- count: `count()`\n",
    "- sum: `sum()`\n",
    "- mean: `mean()`\n",
    "- median: `median()`\n",
    "- minimum: `min()`\n",
    "- maximum: `max()`\n",
    "- product: `prod()`\n",
    "- percent change: `pct_change()`\n",
    "- ranking: `rank()`\n",
    "- standard deviation: `std()`\n",
    "- variance: `var()`\n",
    "- covariance: `cov()`\n",
    "- correlation: `corr()`\n",
    "- quantile: `quantile()`\n",
    "- cummulative sum: `cumsum()`\n",
    "- cummulative product: `cumprod()`\n",
    "- cummulative minimum: `cummin()`\n",
    "- cummulative maximum: `cummax()`\n",
    "- label of minimum: `idxmin()`\n",
    "- label of maximum: `idxmax()`\n",
    "- sample: `sample()`\n",
    "- clipping: `clip()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3><i class=\"fa fa-book\"></i> Further reading</h3>\n",
    "    <ul>\n",
    "        <li><a href='https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#computations-descriptive-stats'>Computations / descriptive stats</a></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3><i class=\"fa fa-edit\"></i>  Exercise 2 &starf;&starf;</h3>\n",
    "    <ul>\n",
    "        <li>Which city has the largest population?</li>\n",
    "        <li>Which city has the lowest elevation?</li>\n",
    "        <li>Which city has the highest elevation?</li>\n",
    "        <li>Which city has the largest number of alternative names? How many names? What are the names?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load notebook4/ex_02.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3><i class=\"fa fa-edit\"></i>  Exercise 3 &starf;&starf;&starf;</h3>\n",
    "    <ul>\n",
    "        <li>Implement a function which finds the closest city given some decimal coordinates (latitude, longitude).</li>\n",
    "        <li>Which city is closest to the crossing between the Equator and the Greenwich Meridian (latitude and longitude are zero)?</li>\n",
    "        <li>Implement a function which computes the decimal latitude or longitude given them in degrees, minutes and seconds.</li>\n",
    "        <li>Pick up a city, check its coordinates in <a href=\"https://en.wikipedia.org\">Wikipedia</a>, then use the combined functions to search it in the dataset.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load notebook4/ex_03.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which city is closest to a given position?\n",
    "\n",
    "def get_city(lat, long):\n",
    "    pass\n",
    "\n",
    "get_city(0.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinate to decimal\n",
    "def dms2gps(d, m, s):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with any world city\n",
    "# north/east = positive, south/west = negative\n",
    "# Area 51: 37° 14′ 06″ north, 115° 48′ 40″ west\n",
    "# see https://fr.wikipedia.org/wiki/Zone_51\n",
    "get_city(dms2gps(37, 14, 6), dms2gps(-115, -48, -40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Discretization of numerical values\n",
    "\n",
    "### 2.3.1 The `cut()` function\n",
    "\n",
    "The `cut()` function discretizes a `Series` object of numerical values according to thresholds and by mapping to categorical values.\n",
    "\n",
    "It returns a `Series` object which shares the same index of the initial one and whose values dtype is categorical and ordered along with the given thresholds.\n",
    "\n",
    "By default the bins include the rightmost edge. This can be changed by using the option `right=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrary discretization of populations in:\n",
    "# - small [0-1,000]\n",
    "# - medium [1,000-10,000]\n",
    "# - large [10,000-100,000]\n",
    "# - big [100,000-1,000,000]\n",
    "# - huge [1,000,000-infinity]\n",
    "var1 = pd.cut(df[\"population\"],\n",
    "               [0, 1000, 10000, 100000, 1000000, np.inf],\n",
    "               labels=[\"small\", \"medium\", \"large\", \"big\", \"huge\"])\n",
    "var1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the use of `np.inf`, a special `numpy` constant to denote $+\\infty$. One can use either `-np.inf` or `np.NINF` to denote $-\\infty$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value counts of var1\n",
    "var1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countplot with seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countplot with var1\n",
    "sns.countplot(x=var1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countplot with log scale with seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countplot with var1 and a log scale\n",
    "ax = sns.countplot(x=var1)\n",
    "ax.set_yscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `qcut()` function\n",
    "\n",
    "The `qcut()` function is a quantile-based discretization function. It discretizes a variable into equal-sized buckets based on rank or based on sample quantiles.\n",
    "\n",
    "It returns a `Series` object which shares the same index the the initial one and whose values dtype is categorical and ordered along with the given labels.\n",
    "\n",
    "By using the option `retbins=True`, the function returns also the array of the different thresholds. The length of the array is +1 than the number of buckets since the last value corresponds to the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrary discretization of populations in 5 \"identical\" buckets: A, B, C, D and E\n",
    "var2 = pd.qcut(df[\"population\"],\n",
    "               5,\n",
    "               labels=[\"E\", \"D\", \"C\", \"B\", \"A\"])\n",
    "var2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value counts of var2\n",
    "var2.value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countplot with var2\n",
    "sns.countplot(x=var2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the labels are the bins which define the different buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no label given\n",
    "var3 = pd.qcut(df[\"population\"], 5)\n",
    "var3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value counts\n",
    "var3.value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option retbins=True\n",
    "_, var4 = pd.qcut(df[\"population\"], 5, retbins=True)\n",
    "var4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3><i class=\"fa fa-plus-square\"></i>  PART 2</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload df\n",
    "df = pd.read_pickle('df_cities_countries.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. The split-apply-combine strategy\n",
    "\n",
    "## 3.1 Introduction\n",
    "\n",
    "The **split-apply-combine strategy** consists in:\n",
    "- Splitting the data into groups based on some criteria.\n",
    "- Applying a function to each group independently.\n",
    "- Combining the results into a data structure.\n",
    "\n",
    "The `groupby()` method splits the data according to identical values of one or several columns (like a pivot table). It returns a `DataFrameGroupBy` object which can be viewed like a dictionary whose:\n",
    "- keys are the modalities of the column(s) used to split the data\n",
    "- and values are subsets of the initial `DataFrame` object, and are either `Series` or `DataFrame` objects.\n",
    "\n",
    "A function (generally an aggregation function) is then applied to each value of the `DataFrameGroupBy` object.\n",
    "\n",
    "The result is finally produced by the combination (or concatenation) of the different values output by the function.\n",
    "\n",
    "This method is similar with the `MapReduce` used in big data architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Standard methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several methods apply to `DataFrameGroupBy` object:\n",
    "\n",
    "- `size()`: Compute group sizes\n",
    "- `count()`: Compute count of group\n",
    "- `mean()`: Compute mean of groups\n",
    "- `sum()`: Compute sum of group values\n",
    "- `std()`: Standard deviation of groups\n",
    "- `var()`: Compute variance of groups\n",
    "- `describe()`: Generates descriptive statistics\n",
    "- `first()`: Compute first of group values\n",
    "- `last()`: Compute last of group values\n",
    "- `nth()`: Take nth value\n",
    "- `min()`: Compute min of group values\n",
    "- `max()`: Compute max of group values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `size()` method returns a `Series` object with the size of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of groups\n",
    "df.groupby('Continent').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can check that sum of sizes is identical to the length of dataframe\n",
    "df.groupby('Continent').size().sum() == len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3><i class=\"fa fa-edit\"></i>  Exercise 4 &starf;</h3>\n",
    "    <ul>\n",
    "        <li>Perform a groupby with the column \"Country\".</li>\n",
    "        <li>Which countries get the maximum and the minimum group size?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load notebook4/ex_04.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `describe()` method also applies to `DataFrameGroupBy` objects. It returns the standard statistics on each numerical column of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe groups\n",
    "df.groupby('Continent').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sum()` method computes the sum of each numerical column for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Continent').sum(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 The `aggregate()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `aggregate()`, or `agg()`, method aggregates all values obtained from groups by passing one, or several function(s), or again different functions by columns. Note that the functions might be used by their name, or taken from the `numpy` module, or again be user-defined.\n",
    "\n",
    "### 3.3.1 Aggregate with a single function\n",
    "\n",
    "When passing a single function, the output is a `DataFrame` or a `DataFrame` object whose columns are those of the initial `DataFrame` object to which the function is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid for all columns\n",
    "df.groupby('Continent').agg('mean', numeric_only=True)  # same as mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Aggregate with a list of functions\n",
    "\n",
    "When passing a list of functions, the output is a `DataFrame` object with hierarchical columns (see below): the first level shows the columns of the initial `DataFrame` object and the second one the name of the functions applied to all column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing a list of functions\n",
    "df.groupby('Continent').agg(['mean', 'std'], numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Aggregate with a dict of functions\n",
    "\n",
    "When passing a dictionary of functions whose keys are column names of the initial `DataFrame` object, the output is also a `DataFrame` object with hierarchical columns: the first level shows the keys and the second one the name of the functions applied to each column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing a dict of functions\n",
    "df.groupby('Continent').agg({'population': 'sum',\n",
    "                             'elevation': 'mean',\n",
    "                             'Country': ['min', 'max']},\n",
    "                            numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3><i class=\"fa fa-edit\"></i>  Exercise 5 &starf;</h3>\n",
    "    <ul>\n",
    "        <li>Compute the minimum and maximum of longitude and latitude by continent.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load notebook4/ex_05.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 The `apply()` method\n",
    "\n",
    "The `apply()` method enables to apply any method to each group. The results will then be combined in a single data structure.\n",
    "\n",
    "For instance, we will compute the city with the largest population by continent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the name with the largest population\n",
    "def top1city(group):\n",
    "    return group.loc[group['population'].idxmax(), 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use with the whole dataframe\n",
    "top1city(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply on group\n",
    "df.groupby('Continent').apply(top1city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3><i class=\"fa fa-edit\"></i>  Exercise 6 &starf;&starf;</h3>\n",
    "    <ul>\n",
    "        <li>Get the top 1 city by country</li>\n",
    "        <li>Get the top 3 cities by continent</li>\n",
    "        <li>Get the top 3 cities and population by continent</li>\n",
    "        <li><b>Hint</b>: If you want to get rid off the extra index, use <code>.droplevel(1)</code> afterwards.\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load notebook4/ex_06.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3><i class=\"fa fa-edit\"></i>  Exercise 7 &starf;&starf;&starf;</h3>\n",
    "    <ul>\n",
    "        <li>Create a function which computes the mean number of alternate names of each city.</li>\n",
    "        <li>Test it on the whole dataset.</li>\n",
    "        <li>Apply this function to the groupby \"feature code\".</li>\n",
    "        <li>Which \"feature code\" gets the largest value?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load notebook4/ex_07.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3><i class=\"fa fa-book\"></i> Further reading</h3>\n",
    "    <ul>\n",
    "        <li><a href='https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html'>Group by: split-apply-combine</a></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Time series\n",
    "\n",
    "\n",
    "This part is a short introduction to time series management with Python. The subject is indeed a complex one.\n",
    "\n",
    "The `datetime` standard module enables to manipulate temporal data with Python.\n",
    "\n",
    "Different modules intend to manage temporal data (`calendar`, `dateutil`, `pytz`, ...); although the `arrow` module intends to unify all those libraries (out of scope).\n",
    "\n",
    "The `datetime` module provides different temporal data types:\n",
    "- **date**: date (year, month, day) in the Gregorian calendar\n",
    "- **time**: time not attached to a date (hours, minutes, seconds, microseconds)\n",
    "- **datetime**: timestamp (date + time)\n",
    "- **timedelta**: duration, difference between 2 dates or 2 times (days, hours, minutes, seconds, microseconds)\n",
    "- **tzinfo**: management of time zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime library\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Temporal objects\n",
    "\n",
    "#### Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date\n",
    "today = datetime.date.today()\n",
    "today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime\n",
    "now = datetime.datetime.now()\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTC datetime\n",
    "now_utc = datetime.datetime.utcnow()\n",
    "now_utc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time delta\n",
    "\n",
    "A `timedelta` object represents a duration which might be expressed in days, hours, minutes, seconds and microseconds.\n",
    "\n",
    "A difference between 2 dates returns a `timedelta` object and conversely the sum or the difference between a `date` object and a `timedelta` object returns a `date` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference between 2 dates\n",
    "today - datetime.date(2024, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of a date and a timedelta\n",
    "now + datetime.timedelta(days=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference between a date and a timedelta\n",
    "now - datetime.timedelta(days=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time zone\n",
    "\n",
    "The `pytz` module implements timezone.\n",
    "\n",
    "A `datetime` object can be converted with the method ` astimezone()` to another `datetime` object within another timezone.\n",
    "\n",
    "As manipulating timezones increase some complexity, the preferred way of dealing with times is to always work in UTC, converting to localtime only when generating output to be read by humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytz\n",
    "from pytz import timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a timezone object\n",
    "tz = timezone('Asia/Shanghai')\n",
    "tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a datetime by using a timezone object\n",
    "now.astimezone(tz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Writing and reading\n",
    "\n",
    "The `strftime()` method and the `strptime()` function enable to write and to read dates in and from several formats with a codification borrowed to the C language.\n",
    "\n",
    "The same codification is used to format an existing date into a string and to build a temporal object from a string in a given format.\n",
    "\n",
    "The number of possible directives unveils the complexity of the subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directives | Comments\n",
    "- | -\n",
    "%a | Day of the week abbreviated\n",
    "%A | Day of the week\n",
    "%w | Day of the week 0 = Sunday ... 6 = Saturday\n",
    "%d | Day of month on 2 digits 01, 02, ..., 31\n",
    "%j | Day of year on 3 digits 001, 002, ..., 366\n",
    "%b | Month abbreviated\n",
    "%B | Month name\n",
    "%m | Month on 2 digits 01, 02, ..., 12\n",
    "%U | Number of week in year (Sunday = first day)\n",
    "%W | Number of week in year (Monday = first day)\n",
    "%y | Year without the century on 2 digits 00, 01, ..., 99\t \n",
    "%Y | Year with the century on 4 digits 0001, 0002, ..., 2018, 2019, ..., 9998, 9999\n",
    "%H | Hour over 24 00, 01, ..., 23\n",
    "%I | Hour over 12 01, 02, ..., 12\n",
    "%p | AM or PM\n",
    "%M | Minute on 2 digits 00, 01, ..., 59\n",
    "%S | Second on 2 digits 00, 01, ..., 59\n",
    "%f | Microsecond on 6 digits 000000, 000001, ..., 999999\n",
    "%z | UTC offset +HHMM or -HHMM\n",
    "%Z | Time zone \n",
    "%c | Representation date and temps\n",
    "%x | Representation date\n",
    "%X | Representation time\n",
    "%% | Character %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime\n",
    "now = datetime.datetime.now()\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day of week\n",
    "now.strftime(\"%A %d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3><i class=\"fa fa-edit\"></i>  Exercise 8 &starf;</h3>\n",
    "    <ul>\n",
    "    <li>Print the current date in the format: \"YYYY-MM-DD/HH:MM:SS\"</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load notebook4/ex_08.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `locale` module helps to manage strings in different languages to get days and months names.\n",
    "\n",
    "You can check the ISO 639-1 codes for languages: https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# managing locale: try to put your own language\n",
    "# sometimes for instance 'fr' is not working, try 'fr_FR' or 'fr_FR.UTF-8'\n",
    "# you can also try with the ISO 639-2 code (with 3 letters)\n",
    "# this depends on your machine not on Python\n",
    "\n",
    "import locale\n",
    "\n",
    "#locale.setlocale(locale.LC_ALL, 'am') # armenian\n",
    "#locale.setlocale(locale.LC_ALL, 'ar') # arabic\n",
    "#locale.setlocale(locale.LC_ALL, 'az') # azeri\n",
    "#locale.setlocale(locale.LC_ALL, 'bn') # bengali\n",
    "#locale.setlocale(locale.LC_ALL, 'da') # danish\n",
    "#locale.setlocale(locale.LC_ALL, 'de') # german\n",
    "#locale.setlocale(locale.LC_ALL, 'es') # spanish\n",
    "#locale.setlocale(locale.LC_ALL, 'en') # english\n",
    "#locale.setlocale(locale.LC_ALL, 'fa') # farsi\n",
    "locale.setlocale(locale.LC_ALL, 'fr') # french\n",
    "#locale.setlocale(locale.LC_ALL, 'ga') # gaelic\n",
    "#locale.setlocale(locale.LC_ALL, 'hi') # hindi\n",
    "#locale.setlocale(locale.LC_ALL, 'he') # hebrew\n",
    "#locale.setlocale(locale.LC_ALL, 'hr') # croatian\n",
    "#locale.setlocale(locale.LC_ALL, 'ig') # igbo\n",
    "#locale.setlocale(locale.LC_ALL, 'it') # italian\n",
    "#locale.setlocale(locale.LC_ALL, 'ja') # japanese\n",
    "#locale.setlocale(locale.LC_ALL, 'lt') # lithuanian \n",
    "#locale.setlocale(locale.LC_ALL, 'ko') # korean\n",
    "#locale.setlocale(locale.LC_ALL, 'nl') # dutch\n",
    "#locale.setlocale(locale.LC_ALL, 'no') # norvegian\n",
    "#locale.setlocale(locale.LC_ALL, 'pt') # portugese\n",
    "#locale.setlocale(locale.LC_ALL, 'ro') # romanian\n",
    "#locale.setlocale(locale.LC_ALL, 'ru') # russian\n",
    "#locale.setlocale(locale.LC_ALL, 'sq') # albanian\n",
    "#locale.setlocale(locale.LC_ALL, 'sr') # serbian\n",
    "#locale.setlocale(locale.LC_ALL, 'th') # thai\n",
    "#locale.setlocale(locale.LC_ALL, 'tr') # turkish\n",
    "#locale.setlocale(locale.LC_ALL, 'ukr') # ukrainian\n",
    "#locale.setlocale(locale.LC_ALL, 'vi') # vietnamian\n",
    "#locale.setlocale(locale.LC_ALL, 'zh') # chinese\n",
    "now.strftime(\"%A %B %d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset locale\n",
    "locale.setlocale(locale.LC_ALL, 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversely, the `strptime()` function takes as arguments a string to decode and another string specifying the format of date end returns a `datetime` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading from format: AA-MM-DD-HH-MM\n",
    "# writing to format : HH:MM DD/MM/YYYY\n",
    "var = datetime.datetime.strptime(\"19-03-01-12-00\", \"%y-%m-%d-%H-%M\")\n",
    "var.strftime(\"%H:%M %d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3><i class=\"fa fa-edit\"></i>  Exercise 9 &starf;</h3>\n",
    "    <ul>\n",
    "        <li>Read a timestamp from the ISO 8601 format: \"YYYY-MM-DDTHH:MM:SS\", e.g., \"2024-09-11T15:00:00\"</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load notebook4/ex_09.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3><i class=\"fa fa-edit\"></i>  Exercise 10 &starf;&starf;&starf;</h3>\n",
    "    <ul>\n",
    "        <li>Load the \"cities500.zip\" DataFrame object, how many timezones do we have?</li>\n",
    "        <li>Switch the \"timezone\" column values to \"timezone\" objects.</li>\n",
    "        <li>Take the current \"datetime\" object (now), convert it with all timezones from the \"timezone\" column, and then produce strings using the format: \"'%Y-%m-%d %H:%M:%S'\"</li>\n",
    "        <li>There are 24 hours in a day, how many different times do we get?</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 1\n",
    "# load cities\n",
    "df = pd.read_csv('data/cities500.zip',\n",
    "                   sep='\\t',\n",
    "                   header=None,\n",
    "                   names=['geonameid', 'name', 'asciiname', 'alternatenames', 'latitude', 'longitude', 'feature class', 'feature code', 'country code', 'cc2', 'admin1 code', 'admin2 code', 'admin3 code', 'admin4 code', 'population', 'elevation', 'dem', 'timezone', 'modification date'],\n",
    "                   dtype={'admin1 code': str, 'admin2 code': str, 'admin3 code': str, 'admin4 code': str},\n",
    "                   keep_default_na=False,\n",
    "                   na_values=['', -9999])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load notebook4/ex_10.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Time series\n",
    "\n",
    "The `pandas` library is able to manage time series.\n",
    "\n",
    "Time series are a huge subject in itself. This paragraph presents only the main concepts:\n",
    "\n",
    "- reading time series\n",
    "- accessing to time series\n",
    "- resampling time series (upsampling)\n",
    "- graphics and rolling windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `to_datetime()` pandas function works like the `strptime()` function in order to convert a string into a date according to a specific format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 6\n",
    "\n",
    "<h3><i class=\"fa fa-database\"></i></h3>\n",
    "\n",
    "Exchange rates :\n",
    "- The first column collect the dates\n",
    "- The following columns collect the exchange rate to EUR by currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset with exchange rates\n",
    "# source: https://www.banque-france.fr\n",
    "\n",
    "# load the file\n",
    "exchange_rates = pd.read_csv(\"data/Webstat_Export.zip\",\n",
    "                        sep=\";\",\n",
    "                        na_values='-',\n",
    "                        decimal=',',\n",
    "                        skiprows=[1, 2],\n",
    "                        usecols=range(43),\n",
    "                        converters={0: lambda x: pd.to_datetime(x, format='%d/%m/%Y', errors='ignore')})\n",
    "exchange_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting currency codes\n",
    "cols = pd.Series(exchange_rates.columns.tolist()).str.extract('\\(([A-Z]{3})\\)', expand=False)\n",
    "exchange_rates.columns = ['Date'] + list(cols[1:])\n",
    "\n",
    "# selecting a few currencies\n",
    "currencies = ['USD', 'CHF', 'GBP', 'JPY', 'BRL', 'CNY']\n",
    "exchange_rates = exchange_rates[['Date'] + currencies]\n",
    "\n",
    "# drop na\n",
    "exchange_rates = exchange_rates.dropna()\n",
    "\n",
    "exchange_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 The `dt` accessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dt` accessor behaves similarly to the `str` accessor for `Series` objects. It enables to access to element-wise datetime attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access to year\n",
    "exchange_rates['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access to month\n",
    "exchange_rates['Date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access to week days\n",
    "exchange_rates['Date'].dt.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3><i class=\"fa fa-edit\"></i>  Exercise 11 &starf;</h3>\n",
    "    <ul>\n",
    "        <li>On which days of week currency rates are issued?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load notebook4/ex_11.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Selecting temporal data\n",
    "\n",
    "When the index is a datetime object, it is possible to select time range from string representations of dates. It works also for slice selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the index as a datetime object\n",
    "exchange_rates = exchange_rates.set_index('Date')\n",
    "exchange_rates = exchange_rates.sort_index()\n",
    "exchange_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a full year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly data\n",
    "exchange_rates.loc['2023']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a full month in a given year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly data\n",
    "exchange_rates.loc['2023/01'] # or exchange_rates['01/2023']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slice selection includes the rightmost period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice selection\n",
    "exchange_rates['12/2023':'01/2024']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 Temporal aggregations\n",
    "\n",
    "It is possible to aggregate data according to a certain period of time by using the `resample()` method with a symbol meaning the period and then to apply an aggregation method.\n",
    "\n",
    "The `resample()` method behaves similarly to the `groupby()` method. It has been adapted to temporal grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly aggregation\n",
    "exchange_rates.resample('A').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly aggregation\n",
    "exchange_rates.resample('A').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly aggregation\n",
    "exchange_rates.resample('M').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Symbolic frequencies which can be used (extract)\n",
    "\n",
    "Here again, the number of possible directives unveils the complexity of the subject..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alias | Offset type | Description\n",
    "- | - | -\n",
    "D | Day | Calendar daily\n",
    "B | BusinessDay | Business daily\n",
    "H | Hour | Hourly\n",
    "T or min | Minute | Minutely\n",
    "S | Second | Secondly\n",
    "L or ms | Milli | Millisecond (1/1000th of 1 second)\n",
    "U | Micro | Microsecond (1/1000000th of 1 second)\n",
    "M | MonthEnd | Last calendar day of month\n",
    "BM | BusinessMonthEnd | Last business day (weekday) of month\n",
    "MS | MonthBegin | First calendar day of month\n",
    "BMS | BusinessMonthBegin | First weekday of month\n",
    "W-MON, W-TUE, ... | Week | Weekly on given day of week: MON, TUE, WED, THU, FRI, SAT, or SUN.\n",
    "Q-JAN, Q-FEB, ... | QuarterEnd | Quarterly dates anchored on last calendar day of each month,for year ending in indicated month: JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, NOV, or DEC.\n",
    "A-JAN, A-FEB, ... | YearEnd | Annual dates anchored on last calendar day of given month: JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, NOV, or DEC.\n",
    "\n",
    "Source: Python for Data Analysis, Wes McKinney, O'Reilly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.4 Temporal graphics\n",
    "\n",
    "It is possible to display directly temporal graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exchange rates\n",
    "exchange_rates.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graphics below, we divide the exchange rates by their respective average to adjust all rates to the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exchange rates divided by their average\n",
    "(exchange_rates / exchange_rates.mean()).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `rolling()` function enables to display graphics with a moving average for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exchange rates divided by their average with a moving average of 30 days\n",
    "(exchange_rates / exchange_rates.mean()).rolling(30).mean().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3><i class=\"fa fa-edit\"></i>  Exercise 12 &starf;&starf;</h3>\n",
    "    <ul>\n",
    "        <li>Display a chart with exchange rates divided by the last known values</li>\n",
    "        <li>Display a chart with exchange rates divided by their means with a moving maximum of 100 days</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load notebook4/ex_12.py\n",
    "\n",
    "# exchange rates divided by their means with a moving maximum of 100 days\n",
    "(exchange_rates / exchange_rates.iloc[-1]).plot();\n",
    "\n",
    "# exchange rates divided by their means with a moving maximum of 100 days\n",
    "(exchange_rates / exchange_rates.mean()).rolling(100).max().plot();\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
